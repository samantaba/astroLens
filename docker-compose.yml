version: "3.9"

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data          # Persist images and database
      - ./weights:/app/weights    # ML model weights
    environment:
      - DATABASE_URL=sqlite:///data/astrolens.db
      - IMAGES_DIR=/app/data/images
      - FAISS_INDEX_PATH=/app/data/faiss.index
      - WEIGHTS_PATH=/app/weights/vit_astrolens.pt
      - OOD_THRESHOLD=10.0
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OLLAMA_URL=${OLLAMA_URL:-http://host.docker.internal:11434}
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Optional: Local LLM with Ollama
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    profiles:
      - local-llm  # Only start with: docker-compose --profile local-llm up

volumes:
  ollama_data:

